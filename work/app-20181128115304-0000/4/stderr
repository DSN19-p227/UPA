18/11/28 11:53:05 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 27623@heming-rdma13
18/11/28 11:53:05 INFO SignalUtils: Registered signal handler for TERM
18/11/28 11:53:05 INFO SignalUtils: Registered signal handler for HUP
18/11/28 11:53:05 INFO SignalUtils: Registered signal handler for INT
18/11/28 11:53:05 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
18/11/28 11:53:05 WARN Utils: Your hostname, heming-rdma13 resolves to a loopback address: 127.0.0.1; using 202.45.128.172 instead (on interface eno1)
18/11/28 11:53:05 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
18/11/28 11:53:05 INFO SecurityManager: Changing view acls to: john
18/11/28 11:53:05 INFO SecurityManager: Changing modify acls to: john
18/11/28 11:53:05 INFO SecurityManager: Changing view acls groups to: 
18/11/28 11:53:05 INFO SecurityManager: Changing modify acls groups to: 
18/11/28 11:53:05 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(john); groups with view permissions: Set(); users  with modify permissions: Set(john); groups with modify permissions: Set()
18/11/28 11:53:05 INFO TransportClientFactory: Successfully created connection to /202.45.128.172:42993 after 29 ms (0 ms spent in bootstraps)
18/11/28 11:53:05 INFO SecurityManager: Changing view acls to: john
18/11/28 11:53:05 INFO SecurityManager: Changing modify acls to: john
18/11/28 11:53:05 INFO SecurityManager: Changing view acls groups to: 
18/11/28 11:53:05 INFO SecurityManager: Changing modify acls groups to: 
18/11/28 11:53:05 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(john); groups with view permissions: Set(); users  with modify permissions: Set(john); groups with modify permissions: Set()
18/11/28 11:53:05 INFO TransportClientFactory: Successfully created connection to /202.45.128.172:42993 after 0 ms (0 ms spent in bootstraps)
18/11/28 11:53:05 INFO DiskBlockManager: Created local directory at /tmp/spark-d3acd6f7-0107-4efe-a283-a8c1c4a35861/executor-a517f579-96ec-4fa8-9e72-3780a65dd941/blockmgr-14932f8d-bf53-4767-a24b-22b6959d826b
18/11/28 11:53:05 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
18/11/28 11:53:05 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@202.45.128.172:42993
18/11/28 11:53:05 INFO WorkerWatcher: Connecting to worker spark://Worker@202.45.128.172:45248
18/11/28 11:53:05 INFO TransportClientFactory: Successfully created connection to /202.45.128.172:45248 after 0 ms (0 ms spent in bootstraps)
18/11/28 11:53:05 INFO WorkerWatcher: Successfully connected to spark://Worker@202.45.128.172:45248
18/11/28 11:53:05 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
18/11/28 11:53:05 INFO Executor: Starting executor ID 4 on host 202.45.128.172
18/11/28 11:53:05 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35437.
18/11/28 11:53:05 INFO NettyBlockTransferService: Server created on 202.45.128.172:35437
18/11/28 11:53:05 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
18/11/28 11:53:05 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(4, 202.45.128.172, 35437, None)
18/11/28 11:53:05 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(4, 202.45.128.172, 35437, None)
18/11/28 11:53:05 INFO BlockManager: Initialized BlockManager: BlockManagerId(4, 202.45.128.172, 35437, None)
18/11/28 11:53:07 INFO CoarseGrainedExecutorBackend: Got assigned task 8
18/11/28 11:53:07 INFO CoarseGrainedExecutorBackend: Got assigned task 18
18/11/28 11:53:07 INFO CoarseGrainedExecutorBackend: Got assigned task 28
18/11/28 11:53:07 INFO CoarseGrainedExecutorBackend: Got assigned task 38
18/11/28 11:53:07 INFO CoarseGrainedExecutorBackend: Got assigned task 48
18/11/28 11:53:07 INFO CoarseGrainedExecutorBackend: Got assigned task 58
18/11/28 11:53:07 INFO CoarseGrainedExecutorBackend: Got assigned task 68
18/11/28 11:53:07 INFO CoarseGrainedExecutorBackend: Got assigned task 78
18/11/28 11:53:07 INFO Executor: Running task 18.0 in stage 0.0 (TID 18)
18/11/28 11:53:07 INFO Executor: Running task 48.0 in stage 0.0 (TID 48)
18/11/28 11:53:07 INFO Executor: Running task 58.0 in stage 0.0 (TID 58)
18/11/28 11:53:07 INFO Executor: Running task 28.0 in stage 0.0 (TID 28)
18/11/28 11:53:07 INFO Executor: Running task 8.0 in stage 0.0 (TID 8)
18/11/28 11:53:07 INFO Executor: Running task 68.0 in stage 0.0 (TID 68)
18/11/28 11:53:07 INFO Executor: Running task 38.0 in stage 0.0 (TID 38)
18/11/28 11:53:07 INFO Executor: Running task 78.0 in stage 0.0 (TID 78)
18/11/28 11:53:07 INFO Executor: Fetching spark://202.45.128.172:42993/jars/spark-examples_2.11-2.2.0.jar with timestamp 1543377184372
18/11/28 11:53:07 INFO TransportClientFactory: Successfully created connection to /202.45.128.172:42993 after 0 ms (0 ms spent in bootstraps)
18/11/28 11:53:07 INFO Utils: Fetching spark://202.45.128.172:42993/jars/spark-examples_2.11-2.2.0.jar to /tmp/spark-d3acd6f7-0107-4efe-a283-a8c1c4a35861/executor-a517f579-96ec-4fa8-9e72-3780a65dd941/spark-e93492d0-7c88-425e-8c58-d794a9363c4e/fetchFileTemp861696550670542699.tmp
18/11/28 11:53:07 INFO Utils: Copying /tmp/spark-d3acd6f7-0107-4efe-a283-a8c1c4a35861/executor-a517f579-96ec-4fa8-9e72-3780a65dd941/spark-e93492d0-7c88-425e-8c58-d794a9363c4e/-8024398161543377184372_cache to /home/john/spark-2.2.0/work/app-20181128115304-0000/4/./spark-examples_2.11-2.2.0.jar
18/11/28 11:53:07 INFO Executor: Adding file:/home/john/spark-2.2.0/work/app-20181128115304-0000/4/./spark-examples_2.11-2.2.0.jar to class loader
18/11/28 11:53:07 INFO TorrentBroadcast: Started reading broadcast variable 1
18/11/28 11:53:07 INFO TransportClientFactory: Successfully created connection to /202.45.128.172:33230 after 0 ms (0 ms spent in bootstraps)
18/11/28 11:53:07 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.6 KB, free 366.3 MB)
18/11/28 11:53:07 INFO TorrentBroadcast: Reading broadcast variable 1 took 53 ms
18/11/28 11:53:07 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 10.6 KB, free 366.3 MB)
18/11/28 11:53:07 INFO CodeGenerator: Code generated in 111.688862 ms
18/11/28 11:53:07 INFO CodeGenerator: Code generated in 10.069802 ms
18/11/28 11:53:07 INFO FileScanRDD: Reading File path: file:///home/john/dataset/pr/com-friendster.ungraph1.txt, range: 772951674-786278427, partition values: [empty row]
18/11/28 11:53:07 INFO FileScanRDD: Reading File path: file:///home/john/dataset/pr/com-friendster.ungraph1.txt, range: 1039486734-1052813487, partition values: [empty row]
18/11/28 11:53:07 INFO FileScanRDD: Reading File path: file:///home/john/dataset/pr/com-friendster.ungraph1.txt, range: 906219204-919545957, partition values: [empty row]
18/11/28 11:53:07 INFO FileScanRDD: Reading File path: file:///home/john/dataset/pr/com-friendster.ungraph1.txt, range: 239881554-253208307, partition values: [empty row]
18/11/28 11:53:07 INFO FileScanRDD: Reading File path: file:///home/john/dataset/pr/com-friendster.ungraph1.txt, range: 373149084-386475837, partition values: [empty row]
18/11/28 11:53:07 INFO FileScanRDD: Reading File path: file:///home/john/dataset/pr/com-friendster.ungraph1.txt, range: 639684144-653010897, partition values: [empty row]
18/11/28 11:53:07 INFO FileScanRDD: Reading File path: file:///home/john/dataset/pr/com-friendster.ungraph1.txt, range: 106614024-119940777, partition values: [empty row]
18/11/28 11:53:07 INFO FileScanRDD: Reading File path: file:///home/john/dataset/pr/com-friendster.ungraph1.txt, range: 506416614-519743367, partition values: [empty row]
18/11/28 11:53:07 INFO CodeGenerator: Code generated in 7.47845 ms
18/11/28 11:53:07 INFO TorrentBroadcast: Started reading broadcast variable 0
18/11/28 11:53:07 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.7 KB, free 366.3 MB)
18/11/28 11:53:07 INFO TorrentBroadcast: Reading broadcast variable 0 took 6 ms
18/11/28 11:53:07 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 293.3 KB, free 366.0 MB)
18/11/28 11:53:08 INFO Executor: Finished task 38.0 in stage 0.0 (TID 38). 1700 bytes result sent to driver
18/11/28 11:53:08 INFO CoarseGrainedExecutorBackend: Got assigned task 87
18/11/28 11:53:08 INFO Executor: Running task 7.0 in stage 1.0 (TID 87)
18/11/28 11:53:09 INFO TorrentBroadcast: Started reading broadcast variable 2
18/11/28 11:53:09 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 6.0 KB, free 366.0 MB)
18/11/28 11:53:09 INFO Executor: Finished task 58.0 in stage 0.0 (TID 58). 1700 bytes result sent to driver
18/11/28 11:53:09 INFO TorrentBroadcast: Reading broadcast variable 2 took 36 ms
18/11/28 11:53:09 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 11.2 KB, free 366.0 MB)
18/11/28 11:53:09 INFO CoarseGrainedExecutorBackend: Got assigned task 91
18/11/28 11:53:09 INFO Executor: Finished task 78.0 in stage 0.0 (TID 78). 2501 bytes result sent to driver
18/11/28 11:53:09 INFO Executor: Running task 11.0 in stage 1.0 (TID 91)
18/11/28 11:53:09 INFO CoarseGrainedExecutorBackend: Got assigned task 92
18/11/28 11:53:09 INFO Executor: Running task 12.0 in stage 1.0 (TID 92)
18/11/28 11:53:09 INFO FileScanRDD: Reading File path: file:///home/john/dataset/pr/com-friendster.ungraph1.txt, range: 146594283-159921036, partition values: [empty row]
18/11/28 11:53:09 INFO FileScanRDD: Reading File path: file:///home/john/dataset/pr/com-friendster.ungraph1.txt, range: 93287271-106614024, partition values: [empty row]
18/11/28 11:53:09 INFO Executor: Finished task 18.0 in stage 0.0 (TID 18). 1700 bytes result sent to driver
18/11/28 11:53:09 INFO Executor: Finished task 28.0 in stage 0.0 (TID 28). 1700 bytes result sent to driver
18/11/28 11:53:09 INFO CoarseGrainedExecutorBackend: Got assigned task 95
18/11/28 11:53:09 INFO Executor: Running task 15.0 in stage 1.0 (TID 95)
18/11/28 11:53:09 INFO Executor: Finished task 8.0 in stage 0.0 (TID 8). 2458 bytes result sent to driver
18/11/28 11:53:09 INFO CoarseGrainedExecutorBackend: Got assigned task 96
18/11/28 11:53:09 INFO Executor: Finished task 48.0 in stage 0.0 (TID 48). 1700 bytes result sent to driver
18/11/28 11:53:09 INFO FileScanRDD: Reading File path: file:///home/john/dataset/pr/com-friendster.ungraph1.txt, range: 159921036-173247789, partition values: [empty row]
18/11/28 11:53:09 INFO CoarseGrainedExecutorBackend: Got assigned task 98
18/11/28 11:53:09 INFO FileScanRDD: Reading File path: file:///home/john/dataset/pr/com-friendster.ungraph1.txt, range: 199901295-213228048, partition values: [empty row]
18/11/28 11:53:09 INFO CoarseGrainedExecutorBackend: Got assigned task 99
18/11/28 11:53:09 INFO Executor: Running task 19.0 in stage 1.0 (TID 99)
18/11/28 11:53:09 INFO FileScanRDD: Reading File path: file:///home/john/dataset/pr/com-friendster.ungraph1.txt, range: 253208307-266535060, partition values: [empty row]
18/11/28 11:53:09 INFO Executor: Running task 16.0 in stage 1.0 (TID 96)
18/11/28 11:53:09 INFO Executor: Running task 18.0 in stage 1.0 (TID 98)
18/11/28 11:53:09 INFO FileScanRDD: Reading File path: file:///home/john/dataset/pr/com-friendster.ungraph1.txt, range: 239881554-253208307, partition values: [empty row]
18/11/28 11:53:09 INFO FileScanRDD: Reading File path: file:///home/john/dataset/pr/com-friendster.ungraph1.txt, range: 213228048-226554801, partition values: [empty row]
18/11/28 11:53:09 INFO Executor: Finished task 68.0 in stage 0.0 (TID 68). 1700 bytes result sent to driver
18/11/28 11:53:09 INFO CoarseGrainedExecutorBackend: Got assigned task 111
18/11/28 11:53:09 INFO Executor: Running task 31.0 in stage 1.0 (TID 111)
18/11/28 11:53:09 INFO FileScanRDD: Reading File path: file:///home/john/dataset/pr/com-friendster.ungraph1.txt, range: 413129343-426456096, partition values: [empty row]
18/11/28 11:53:09 INFO Executor: Finished task 16.0 in stage 1.0 (TID 96). 1743 bytes result sent to driver
18/11/28 11:53:09 INFO CoarseGrainedExecutorBackend: Got assigned task 159
18/11/28 11:53:09 INFO Executor: Running task 79.0 in stage 1.0 (TID 159)
18/11/28 11:53:09 INFO FileScanRDD: Reading File path: file:///home/john/dataset/pr/com-friendster.ungraph1.txt, range: 1052813487-1061945987, partition values: [empty row]
18/11/28 11:53:10 INFO Executor: Finished task 18.0 in stage 1.0 (TID 98). 1700 bytes result sent to driver
18/11/28 11:53:10 INFO Executor: Finished task 15.0 in stage 1.0 (TID 95). 1743 bytes result sent to driver
18/11/28 11:53:10 INFO Executor: Finished task 7.0 in stage 1.0 (TID 87). 2458 bytes result sent to driver
18/11/28 11:53:10 INFO Executor: Finished task 19.0 in stage 1.0 (TID 99). 1700 bytes result sent to driver
18/11/28 11:53:10 INFO Executor: Finished task 11.0 in stage 1.0 (TID 91). 1700 bytes result sent to driver
18/11/28 11:53:10 INFO Executor: Finished task 12.0 in stage 1.0 (TID 92). 1700 bytes result sent to driver
18/11/28 11:53:10 INFO Executor: Finished task 31.0 in stage 1.0 (TID 111). 1700 bytes result sent to driver
18/11/28 11:53:10 INFO Executor: Finished task 79.0 in stage 1.0 (TID 159). 1700 bytes result sent to driver
18/11/28 11:53:10 INFO CoarseGrainedExecutorBackend: Got assigned task 165
18/11/28 11:53:10 INFO Executor: Running task 5.0 in stage 2.0 (TID 165)
18/11/28 11:53:10 INFO CoarseGrainedExecutorBackend: Got assigned task 175
18/11/28 11:53:10 INFO Executor: Running task 15.0 in stage 2.0 (TID 175)
18/11/28 11:53:10 INFO CoarseGrainedExecutorBackend: Got assigned task 185
18/11/28 11:53:10 INFO Executor: Running task 25.0 in stage 2.0 (TID 185)
18/11/28 11:53:10 INFO CoarseGrainedExecutorBackend: Got assigned task 195
18/11/28 11:53:10 INFO CoarseGrainedExecutorBackend: Got assigned task 205
18/11/28 11:53:10 INFO CoarseGrainedExecutorBackend: Got assigned task 215
18/11/28 11:53:10 INFO MapOutputTrackerWorker: Updating epoch to 2 and clearing cache
18/11/28 11:53:10 INFO Executor: Running task 55.0 in stage 2.0 (TID 215)
18/11/28 11:53:10 INFO TorrentBroadcast: Started reading broadcast variable 3
18/11/28 11:53:10 INFO Executor: Running task 35.0 in stage 2.0 (TID 195)
18/11/28 11:53:10 INFO Executor: Running task 45.0 in stage 2.0 (TID 205)
18/11/28 11:53:10 INFO CoarseGrainedExecutorBackend: Got assigned task 225
18/11/28 11:53:10 INFO Executor: Running task 65.0 in stage 2.0 (TID 225)
18/11/28 11:53:10 INFO CoarseGrainedExecutorBackend: Got assigned task 235
18/11/28 11:53:10 INFO Executor: Running task 75.0 in stage 2.0 (TID 235)
18/11/28 11:53:10 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.3 KB, free 366.0 MB)
18/11/28 11:53:10 INFO TorrentBroadcast: Reading broadcast variable 3 took 22 ms
18/11/28 11:53:10 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 3.9 KB, free 366.0 MB)
18/11/28 11:53:10 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them
18/11/28 11:53:10 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them
18/11/28 11:53:10 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them
18/11/28 11:53:10 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them
18/11/28 11:53:10 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them
18/11/28 11:53:10 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them
18/11/28 11:53:10 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them
18/11/28 11:53:10 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them
18/11/28 11:53:10 INFO MapOutputTrackerWorker: Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@202.45.128.172:42993)
18/11/28 11:53:10 INFO MapOutputTrackerWorker: Got the output locations
18/11/28 11:53:10 INFO ShuffleBlockFetcherIterator: Getting 80 non-empty blocks out of 80 blocks
18/11/28 11:53:10 INFO ShuffleBlockFetcherIterator: Getting 80 non-empty blocks out of 80 blocks
18/11/28 11:53:10 INFO ShuffleBlockFetcherIterator: Getting 80 non-empty blocks out of 80 blocks
18/11/28 11:53:10 INFO ShuffleBlockFetcherIterator: Getting 80 non-empty blocks out of 80 blocks
18/11/28 11:53:10 INFO ShuffleBlockFetcherIterator: Getting 80 non-empty blocks out of 80 blocks
18/11/28 11:53:10 INFO ShuffleBlockFetcherIterator: Getting 80 non-empty blocks out of 80 blocks
18/11/28 11:53:10 INFO ShuffleBlockFetcherIterator: Getting 80 non-empty blocks out of 80 blocks
18/11/28 11:53:10 INFO ShuffleBlockFetcherIterator: Getting 80 non-empty blocks out of 80 blocks
18/11/28 11:53:10 INFO TransportClientFactory: Successfully created connection to /202.45.128.175:39753 after 18 ms (0 ms spent in bootstraps)
18/11/28 11:53:10 INFO TransportClientFactory: Successfully created connection to /202.45.128.178:43328 after 19 ms (0 ms spent in bootstraps)
18/11/28 11:53:10 INFO TransportClientFactory: Successfully created connection to /202.45.128.176:35344 after 20 ms (0 ms spent in bootstraps)
18/11/28 11:53:10 INFO TransportClientFactory: Successfully created connection to /202.45.128.171:45287 after 36 ms (0 ms spent in bootstraps)
18/11/28 11:53:10 INFO TransportClientFactory: Successfully created connection to /202.45.128.174:33304 after 53 ms (0 ms spent in bootstraps)
18/11/28 11:53:10 INFO TransportClientFactory: Successfully created connection to /202.45.128.177:33442 after 54 ms (0 ms spent in bootstraps)
18/11/28 11:53:10 INFO TransportClientFactory: Successfully created connection to /202.45.128.173:44344 after 55 ms (0 ms spent in bootstraps)
18/11/28 11:53:10 INFO TransportClientFactory: Successfully created connection to /202.45.128.179:41660 after 79 ms (0 ms spent in bootstraps)
18/11/28 11:53:10 INFO TransportClientFactory: Successfully created connection to /202.45.128.180:35948 after 79 ms (0 ms spent in bootstraps)
18/11/28 11:53:10 INFO ShuffleBlockFetcherIterator: Started 9 remote fetches in 111 ms
18/11/28 11:53:10 INFO ShuffleBlockFetcherIterator: Started 9 remote fetches in 115 ms
18/11/28 11:53:10 INFO ShuffleBlockFetcherIterator: Started 9 remote fetches in 112 ms
18/11/28 11:53:10 INFO ShuffleBlockFetcherIterator: Started 9 remote fetches in 107 ms
18/11/28 11:53:10 INFO ShuffleBlockFetcherIterator: Started 9 remote fetches in 115 ms
18/11/28 11:53:10 INFO ShuffleBlockFetcherIterator: Started 9 remote fetches in 113 ms
18/11/28 11:53:10 INFO ShuffleBlockFetcherIterator: Started 9 remote fetches in 116 ms
18/11/28 11:53:10 INFO ShuffleBlockFetcherIterator: Started 9 remote fetches in 115 ms
18/11/28 11:53:32 ERROR Executor: Exception in task 35.0 in stage 2.0 (TID 195)
java.lang.OutOfMemoryError: GC overhead limit exceeded
	at scala.collection.mutable.ResizableArray$class.$init$(ResizableArray.scala:32)
	at scala.collection.mutable.ArrayBuffer.<init>(ArrayBuffer.scala:49)
	at scala.collection.mutable.ArrayBuffer.<init>(ArrayBuffer.scala:63)
	at org.apache.spark.rdd.SubtractedRDD.org$apache$spark$rdd$SubtractedRDD$$getSeq$1(SubtractedRDD.scala:97)
	at org.apache.spark.rdd.SubtractedRDD$$anonfun$compute$1.apply(SubtractedRDD.scala:119)
	at org.apache.spark.rdd.SubtractedRDD$$anonfun$compute$1.apply(SubtractedRDD.scala:119)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at org.apache.spark.rdd.SubtractedRDD.integrate$1(SubtractedRDD.scala:114)
	at org.apache.spark.rdd.SubtractedRDD.compute(SubtractedRDD.scala:119)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
18/11/28 11:53:32 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker for task 195,5,main]
java.lang.OutOfMemoryError: GC overhead limit exceeded
	at scala.collection.mutable.ResizableArray$class.$init$(ResizableArray.scala:32)
	at scala.collection.mutable.ArrayBuffer.<init>(ArrayBuffer.scala:49)
	at scala.collection.mutable.ArrayBuffer.<init>(ArrayBuffer.scala:63)
	at org.apache.spark.rdd.SubtractedRDD.org$apache$spark$rdd$SubtractedRDD$$getSeq$1(SubtractedRDD.scala:97)
	at org.apache.spark.rdd.SubtractedRDD$$anonfun$compute$1.apply(SubtractedRDD.scala:119)
	at org.apache.spark.rdd.SubtractedRDD$$anonfun$compute$1.apply(SubtractedRDD.scala:119)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at org.apache.spark.rdd.SubtractedRDD.integrate$1(SubtractedRDD.scala:114)
	at org.apache.spark.rdd.SubtractedRDD.compute(SubtractedRDD.scala:119)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
18/11/28 11:53:32 INFO CoarseGrainedExecutorBackend: Got assigned task 241
18/11/28 11:53:32 INFO Executor: Running task 36.1 in stage 2.0 (TID 241)
18/11/28 11:53:32 INFO DiskBlockManager: Shutdown hook called
18/11/28 11:53:36 ERROR TransportResponseHandler: Still have 13 requests outstanding when connection from /202.45.128.175:39753 is closed
18/11/28 11:53:36 INFO RetryingBlockFetcher: Retrying fetch (1/3) for 8 outstanding blocks after 5000 ms
18/11/28 11:53:36 ERROR TransportRequestHandler: Error sending result ChunkFetchSuccess{streamChunkId=StreamChunkId{streamId=1014358389071, chunkIndex=4}, buffer=FileSegmentManagedBuffer{file=/tmp/spark-d3acd6f7-0107-4efe-a283-a8c1c4a35861/executor-a517f579-96ec-4fa8-9e72-3780a65dd941/blockmgr-14932f8d-bf53-4767-a24b-22b6959d826b/2e/shuffle_0_48_0.data, offset=118101, length=117659}} to /202.45.128.171:48724; closing connection
java.io.FileNotFoundException: /tmp/spark-d3acd6f7-0107-4efe-a283-a8c1c4a35861/executor-a517f579-96ec-4fa8-9e72-3780a65dd941/blockmgr-14932f8d-bf53-4767-a24b-22b6959d826b/2e/shuffle_0_48_0.data (No such file or directory)
	at java.io.RandomAccessFile.open0(Native Method)
	at java.io.RandomAccessFile.open(RandomAccessFile.java:316)
	at java.io.RandomAccessFile.<init>(RandomAccessFile.java:243)
	at io.netty.channel.DefaultFileRegion.open(DefaultFileRegion.java:103)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:137)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/11/28 11:53:36 ERROR TransportRequestHandler: Error sending result ChunkFetchSuccess{streamChunkId=StreamChunkId{streamId=1014358389071, chunkIndex=5}, buffer=FileSegmentManagedBuffer{file=/tmp/spark-d3acd6f7-0107-4efe-a283-a8c1c4a35861/executor-a517f579-96ec-4fa8-9e72-3780a65dd941/blockmgr-14932f8d-bf53-4767-a24b-22b6959d826b/11/shuffle_0_58_0.data, offset=117105, length=117606}} to /202.45.128.171:48724; closing connection
java.io.FileNotFoundException: /tmp/spark-d3acd6f7-0107-4efe-a283-a8c1c4a35861/executor-a517f579-96ec-4fa8-9e72-3780a65dd941/blockmgr-14932f8d-bf53-4767-a24b-22b6959d826b/2e/shuffle_0_48_0.data (No such file or directory)
	at java.io.RandomAccessFile.open0(Native Method)
	at java.io.RandomAccessFile.open(RandomAccessFile.java:316)
	at java.io.RandomAccessFile.<init>(RandomAccessFile.java:243)
	at io.netty.channel.DefaultFileRegion.open(DefaultFileRegion.java:103)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:137)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/11/28 11:53:36 ERROR TransportRequestHandler: Error sending result ChunkFetchSuccess{streamChunkId=StreamChunkId{streamId=1014358389071, chunkIndex=6}, buffer=FileSegmentManagedBuffer{file=/tmp/spark-d3acd6f7-0107-4efe-a283-a8c1c4a35861/executor-a517f579-96ec-4fa8-9e72-3780a65dd941/blockmgr-14932f8d-bf53-4767-a24b-22b6959d826b/10/shuffle_0_68_0.data, offset=117349, length=118800}} to /202.45.128.171:48724; closing connection
java.io.FileNotFoundException: /tmp/spark-d3acd6f7-0107-4efe-a283-a8c1c4a35861/executor-a517f579-96ec-4fa8-9e72-3780a65dd941/blockmgr-14932f8d-bf53-4767-a24b-22b6959d826b/2e/shuffle_0_48_0.data (No such file or directory)
	at java.io.RandomAccessFile.open0(Native Method)
	at java.io.RandomAccessFile.open(RandomAccessFile.java:316)
	at java.io.RandomAccessFile.<init>(RandomAccessFile.java:243)
	at io.netty.channel.DefaultFileRegion.open(DefaultFileRegion.java:103)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:137)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/11/28 11:53:36 ERROR TransportRequestHandler: Error sending result ChunkFetchSuccess{streamChunkId=StreamChunkId{streamId=1014358389071, chunkIndex=7}, buffer=FileSegmentManagedBuffer{file=/tmp/spark-d3acd6f7-0107-4efe-a283-a8c1c4a35861/executor-a517f579-96ec-4fa8-9e72-3780a65dd941/blockmgr-14932f8d-bf53-4767-a24b-22b6959d826b/31/shuffle_0_78_0.data, offset=117105, length=120037}} to /202.45.128.171:48724; closing connection
java.io.FileNotFoundException: /tmp/spark-d3acd6f7-0107-4efe-a283-a8c1c4a35861/executor-a517f579-96ec-4fa8-9e72-3780a65dd941/blockmgr-14932f8d-bf53-4767-a24b-22b6959d826b/2e/shuffle_0_48_0.data (No such file or directory)
	at java.io.RandomAccessFile.open0(Native Method)
	at java.io.RandomAccessFile.open(RandomAccessFile.java:316)
	at java.io.RandomAccessFile.<init>(RandomAccessFile.java:243)
	at io.netty.channel.DefaultFileRegion.open(DefaultFileRegion.java:103)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:137)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/11/28 11:53:36 ERROR TransportRequestHandler: Error sending result RpcResponse{requestId=6980313050176857507, body=NioManagedBuffer{buf=java.nio.HeapByteBuffer[pos=0 lim=13 cap=13]}} to /202.45.128.171:48724; closing connection
java.io.FileNotFoundException: /tmp/spark-d3acd6f7-0107-4efe-a283-a8c1c4a35861/executor-a517f579-96ec-4fa8-9e72-3780a65dd941/blockmgr-14932f8d-bf53-4767-a24b-22b6959d826b/2e/shuffle_0_48_0.data (No such file or directory)
	at java.io.RandomAccessFile.open0(Native Method)
	at java.io.RandomAccessFile.open(RandomAccessFile.java:316)
	at java.io.RandomAccessFile.<init>(RandomAccessFile.java:243)
	at io.netty.channel.DefaultFileRegion.open(DefaultFileRegion.java:103)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:137)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/11/28 11:53:36 ERROR TransportRequestHandler: Error sending result RpcResponse{requestId=5741079281996857428, body=NioManagedBuffer{buf=java.nio.HeapByteBuffer[pos=0 lim=13 cap=13]}} to /202.45.128.171:48724; closing connection
java.io.FileNotFoundException: /tmp/spark-d3acd6f7-0107-4efe-a283-a8c1c4a35861/executor-a517f579-96ec-4fa8-9e72-3780a65dd941/blockmgr-14932f8d-bf53-4767-a24b-22b6959d826b/2e/shuffle_0_48_0.data (No such file or directory)
	at java.io.RandomAccessFile.open0(Native Method)
	at java.io.RandomAccessFile.open(RandomAccessFile.java:316)
	at java.io.RandomAccessFile.<init>(RandomAccessFile.java:243)
	at io.netty.channel.DefaultFileRegion.open(DefaultFileRegion.java:103)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:137)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/11/28 11:53:36 ERROR TransportRequestHandler: Error sending result RpcResponse{requestId=6262318357626157817, body=NioManagedBuffer{buf=java.nio.HeapByteBuffer[pos=0 lim=13 cap=13]}} to /202.45.128.171:48724; closing connection
java.io.FileNotFoundException: /tmp/spark-d3acd6f7-0107-4efe-a283-a8c1c4a35861/executor-a517f579-96ec-4fa8-9e72-3780a65dd941/blockmgr-14932f8d-bf53-4767-a24b-22b6959d826b/2e/shuffle_0_48_0.data (No such file or directory)
	at java.io.RandomAccessFile.open0(Native Method)
	at java.io.RandomAccessFile.open(RandomAccessFile.java:316)
	at java.io.RandomAccessFile.<init>(RandomAccessFile.java:243)
	at io.netty.channel.DefaultFileRegion.open(DefaultFileRegion.java:103)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:137)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/11/28 11:53:37 ERROR TransportRequestHandler: Error sending result ChunkFetchSuccess{streamChunkId=StreamChunkId{streamId=1014358389008, chunkIndex=4}, buffer=FileSegmentManagedBuffer{file=/tmp/spark-d3acd6f7-0107-4efe-a283-a8c1c4a35861/executor-a517f579-96ec-4fa8-9e72-3780a65dd941/blockmgr-14932f8d-bf53-4767-a24b-22b6959d826b/2e/shuffle_0_48_0.data, offset=6089905, length=117590}} to /202.45.128.177:60888; closing connection
java.io.FileNotFoundException: /tmp/spark-d3acd6f7-0107-4efe-a283-a8c1c4a35861/executor-a517f579-96ec-4fa8-9e72-3780a65dd941/blockmgr-14932f8d-bf53-4767-a24b-22b6959d826b/2e/shuffle_0_48_0.data (No such file or directory)
	at java.io.RandomAccessFile.open0(Native Method)
	at java.io.RandomAccessFile.open(RandomAccessFile.java:316)
	at java.io.RandomAccessFile.<init>(RandomAccessFile.java:243)
	at io.netty.channel.DefaultFileRegion.open(DefaultFileRegion.java:103)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:137)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/11/28 11:53:37 ERROR TransportRequestHandler: Error sending result ChunkFetchSuccess{streamChunkId=StreamChunkId{streamId=1014358389026, chunkIndex=4}, buffer=FileSegmentManagedBuffer{file=/tmp/spark-d3acd6f7-0107-4efe-a283-a8c1c4a35861/executor-a517f579-96ec-4fa8-9e72-3780a65dd941/blockmgr-14932f8d-bf53-4767-a24b-22b6959d826b/2e/shuffle_0_48_0.data, offset=8081730, length=117329}} to /202.45.128.179:35082; closing connection
java.io.FileNotFoundException: /tmp/spark-d3acd6f7-0107-4efe-a283-a8c1c4a35861/executor-a517f579-96ec-4fa8-9e72-3780a65dd941/blockmgr-14932f8d-bf53-4767-a24b-22b6959d826b/2e/shuffle_0_48_0.data (No such file or directory)
	at java.io.RandomAccessFile.open0(Native Method)
	at java.io.RandomAccessFile.open(RandomAccessFile.java:316)
	at java.io.RandomAccessFile.<init>(RandomAccessFile.java:243)
	at io.netty.channel.DefaultFileRegion.open(DefaultFileRegion.java:103)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:137)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/11/28 11:53:37 ERROR TransportRequestHandler: Error sending result ChunkFetchSuccess{streamChunkId=StreamChunkId{streamId=1014358389026, chunkIndex=5}, buffer=FileSegmentManagedBuffer{file=/tmp/spark-d3acd6f7-0107-4efe-a283-a8c1c4a35861/executor-a517f579-96ec-4fa8-9e72-3780a65dd941/blockmgr-14932f8d-bf53-4767-a24b-22b6959d826b/11/shuffle_0_58_0.data, offset=8074360, length=116816}} to /202.45.128.179:35082; closing connection
java.io.FileNotFoundException: /tmp/spark-d3acd6f7-0107-4efe-a283-a8c1c4a35861/executor-a517f579-96ec-4fa8-9e72-3780a65dd941/blockmgr-14932f8d-bf53-4767-a24b-22b6959d826b/2e/shuffle_0_48_0.data (No such file or directory)
	at java.io.RandomAccessFile.open0(Native Method)
	at java.io.RandomAccessFile.open(RandomAccessFile.java:316)
	at java.io.RandomAccessFile.<init>(RandomAccessFile.java:243)
	at io.netty.channel.DefaultFileRegion.open(DefaultFileRegion.java:103)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:137)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/11/28 11:53:37 ERROR TransportRequestHandler: Error sending result ChunkFetchSuccess{streamChunkId=StreamChunkId{streamId=1014358389026, chunkIndex=6}, buffer=FileSegmentManagedBuffer{file=/tmp/spark-d3acd6f7-0107-4efe-a283-a8c1c4a35861/executor-a517f579-96ec-4fa8-9e72-3780a65dd941/blockmgr-14932f8d-bf53-4767-a24b-22b6959d826b/10/shuffle_0_68_0.data, offset=8153149, length=116579}} to /202.45.128.179:35082; closing connection
java.io.FileNotFoundException: /tmp/spark-d3acd6f7-0107-4efe-a283-a8c1c4a35861/executor-a517f579-96ec-4fa8-9e72-3780a65dd941/blockmgr-14932f8d-bf53-4767-a24b-22b6959d826b/2e/shuffle_0_48_0.data (No such file or directory)
	at java.io.RandomAccessFile.open0(Native Method)
	at java.io.RandomAccessFile.open(RandomAccessFile.java:316)
	at java.io.RandomAccessFile.<init>(RandomAccessFile.java:243)
	at io.netty.channel.DefaultFileRegion.open(DefaultFileRegion.java:103)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:137)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/11/28 11:53:38 ERROR TransportRequestHandler: Error sending result ChunkFetchSuccess{streamChunkId=StreamChunkId{streamId=1014358389026, chunkIndex=7}, buffer=FileSegmentManagedBuffer{file=/tmp/spark-d3acd6f7-0107-4efe-a283-a8c1c4a35861/executor-a517f579-96ec-4fa8-9e72-3780a65dd941/blockmgr-14932f8d-bf53-4767-a24b-22b6959d826b/31/shuffle_0_78_0.data, offset=8175550, length=118208}} to /202.45.128.179:35082; closing connection
java.io.FileNotFoundException: /tmp/spark-d3acd6f7-0107-4efe-a283-a8c1c4a35861/executor-a517f579-96ec-4fa8-9e72-3780a65dd941/blockmgr-14932f8d-bf53-4767-a24b-22b6959d826b/2e/shuffle_0_48_0.data (No such file or directory)
	at java.io.RandomAccessFile.open0(Native Method)
	at java.io.RandomAccessFile.open(RandomAccessFile.java:316)
	at java.io.RandomAccessFile.<init>(RandomAccessFile.java:243)
	at io.netty.channel.DefaultFileRegion.open(DefaultFileRegion.java:103)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:137)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:748)
18/11/28 11:53:52 ERROR TransportRequestHandler: Error sending result ChunkFetchSuccess{streamChunkId=StreamChunkId{streamId=1014358389064, chunkIndex=4}, buffer=FileSegmentManagedBuffer{file=/tmp/spark-d3acd6f7-0107-4efe-a283-a8c1c4a35861/executor-a517f579-96ec-4fa8-9e72-3780a65dd941/blockmgr-14932f8d-bf53-4767-a24b-22b6959d826b/2e/shuffle_0_48_0.data, offset=1876719, length=116413}} to /202.45.128.174:43194; closing connection
java.io.FileNotFoundException: /tmp/spark-d3acd6f7-0107-4efe-a283-a8c1c4a35861/executor-a517f579-96ec-4fa8-9e72-3780a65dd941/blockmgr-14932f8d-bf53-4767-a24b-22b6959d826b/2e/shuffle_0_48_0.data (No such file or directory)
	at java.io.RandomAccessFile.open0(Native Method)
	at java.io.RandomAccessFile.open(RandomAccessFile.java:316)
	at java.io.RandomAccessFile.<init>(RandomAccessFile.java:243)
	at io.netty.channel.DefaultFileRegion.open(DefaultFileRegion.java:103)
	at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:137)
	at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121)
	at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287)
	at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237)
	at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.flush0(AbstractNioChannel.java:313)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.flush(AbstractChannel.java:770)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.flush(DefaultChannelPipeline.java:1256)
	at io.netty.channel.AbstractChannelHandlerContext.invokeFlush0(AbstractChannelHandlerContext.java:771)
	at io.netty.channel.AbstractChannelHandlerContext.invokeFlush(AbstractChannelHandlerContext.java:763)
	at io.netty.channel.AbstractChannelHandlerContext.flush(AbstractChannelHandlerContext.java:744)
	at io.netty.channel.ChannelOutboundHandlerAdapter.flush(ChannelOutboundHandlerAdapter.java:115)
	at io.netty.channel.AbstractChannelHandlerContext.invokeFlush0(AbstractChannelHandlerContext.java:771)
	at io.netty.channel.AbstractChannelHandlerContext.invokeFlush(AbstractChannelHandlerContext.java:763)
	at io.netty.channel.AbstractChannelHandlerContext.flush(AbstractChannelHandlerContext.java:744)
	at io.netty.channel.ChannelDuplexHandler.flush(ChannelDuplexHandler.java:117)
	at io.netty.channel.AbstractChannelHandlerContext.invokeFlush0(AbstractChannelHandlerContext.java:771)
	at io.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:797)
	at io.netty.channel.AbstractChannelHandlerContext.write(AbstractChannelHandlerContext.java:808)
	at io.netty.channel.AbstractChannelHandlerContext.writeAndFlush(AbstractChannelHandlerContext.java:789)
	at io.netty.channel.AbstractChannelHandlerContext.writeAndFlush(AbstractChannelHandlerContext.java:825)
	at io.netty.channel.DefaultChannelPipeline.writeAndFlush(DefaultChannelPipeline.java:1017)
	at io.netty.channel.AbstractChannel.writeAndFlush(AbstractChannel.java:256)
	at org.apache.spark.network.server.TransportRequestHandler.respond(TransportRequestHandler.java:192)
	at org.apache.spark.network.server.TransportRequestHandler.processFetchRequest(TransportRequestHandler.java:133)
	at org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:103)
	at org.apache.spark.network.server.TransportChannelHandler.channelRead(TransportChannelHandler.java:118)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:287)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:85)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1294)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:911)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:131)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:643)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.