18/11/28 20:12:07 ERROR Executor: Exception in task 0.0 in stage 2.0 (TID 2)
java.lang.NumberFormatException: For input string: "-0.99099,-0.48738,-0.15665,-0.23876,-0.62818,-0.55491,-0.21979,0.10086,0.18321,-0.26795,0"
	at sun.misc.FloatingDecimal.readJavaFormatString(FloatingDecimal.java:2043)
	at sun.misc.FloatingDecimal.parseDouble(FloatingDecimal.java:110)
	at java.lang.Double.parseDouble(Double.java:538)
	at scala.collection.immutable.StringLike$class.toDouble(StringLike.scala:284)
	at scala.collection.immutable.StringOps.toDouble(StringOps.scala:29)
	at org.apache.spark.examples.SparkHdfsLRDP$.parsePoint(SparkHdfsLRDP.scala:44)
	at org.apache.spark.examples.SparkHdfsLRDP$$anonfun$1.apply(SparkHdfsLRDP.scala:81)
	at org.apache.spark.examples.SparkHdfsLRDP$$anonfun$1.apply(SparkHdfsLRDP.scala:81)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.TraversableOnce$class.reduceLeft(TraversableOnce.scala:185)
	at scala.collection.AbstractIterator.reduceLeft(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$reduce$1$$anonfun$15.apply(RDD.scala:1012)
	at org.apache.spark.rdd.RDD$$anonfun$reduce$1$$anonfun$15.apply(RDD.scala:1010)
	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:2118)
	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:2118)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
18/11/28 20:12:07 ERROR Executor: Exception in task 0.1 in stage 2.0 (TID 3)
java.lang.NumberFormatException: For input string: "-0.99099,-0.48738,-0.15665,-0.23876,-0.62818,-0.55491,-0.21979,0.10086,0.18321,-0.26795,0"
	at sun.misc.FloatingDecimal.readJavaFormatString(FloatingDecimal.java:2043)
	at sun.misc.FloatingDecimal.parseDouble(FloatingDecimal.java:110)
	at java.lang.Double.parseDouble(Double.java:538)
	at scala.collection.immutable.StringLike$class.toDouble(StringLike.scala:284)
	at scala.collection.immutable.StringOps.toDouble(StringOps.scala:29)
	at org.apache.spark.examples.SparkHdfsLRDP$.parsePoint(SparkHdfsLRDP.scala:44)
	at org.apache.spark.examples.SparkHdfsLRDP$$anonfun$1.apply(SparkHdfsLRDP.scala:81)
	at org.apache.spark.examples.SparkHdfsLRDP$$anonfun$1.apply(SparkHdfsLRDP.scala:81)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.TraversableOnce$class.reduceLeft(TraversableOnce.scala:185)
	at scala.collection.AbstractIterator.reduceLeft(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$reduce$1$$anonfun$15.apply(RDD.scala:1012)
	at org.apache.spark.rdd.RDD$$anonfun$reduce$1$$anonfun$15.apply(RDD.scala:1010)
	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:2118)
	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:2118)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
18/11/28 20:12:07 ERROR Executor: Exception in task 0.2 in stage 2.0 (TID 4)
java.lang.NumberFormatException: For input string: "-0.99099,-0.48738,-0.15665,-0.23876,-0.62818,-0.55491,-0.21979,0.10086,0.18321,-0.26795,0"
	at sun.misc.FloatingDecimal.readJavaFormatString(FloatingDecimal.java:2043)
	at sun.misc.FloatingDecimal.parseDouble(FloatingDecimal.java:110)
	at java.lang.Double.parseDouble(Double.java:538)
	at scala.collection.immutable.StringLike$class.toDouble(StringLike.scala:284)
	at scala.collection.immutable.StringOps.toDouble(StringOps.scala:29)
	at org.apache.spark.examples.SparkHdfsLRDP$.parsePoint(SparkHdfsLRDP.scala:44)
	at org.apache.spark.examples.SparkHdfsLRDP$$anonfun$1.apply(SparkHdfsLRDP.scala:81)
	at org.apache.spark.examples.SparkHdfsLRDP$$anonfun$1.apply(SparkHdfsLRDP.scala:81)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.TraversableOnce$class.reduceLeft(TraversableOnce.scala:185)
	at scala.collection.AbstractIterator.reduceLeft(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$reduce$1$$anonfun$15.apply(RDD.scala:1012)
	at org.apache.spark.rdd.RDD$$anonfun$reduce$1$$anonfun$15.apply(RDD.scala:1010)
	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:2118)
	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:2118)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
18/11/28 20:12:07 ERROR Executor: Exception in task 0.3 in stage 2.0 (TID 5)
java.lang.NumberFormatException: For input string: "-0.99099,-0.48738,-0.15665,-0.23876,-0.62818,-0.55491,-0.21979,0.10086,0.18321,-0.26795,0"
	at sun.misc.FloatingDecimal.readJavaFormatString(FloatingDecimal.java:2043)
	at sun.misc.FloatingDecimal.parseDouble(FloatingDecimal.java:110)
	at java.lang.Double.parseDouble(Double.java:538)
	at scala.collection.immutable.StringLike$class.toDouble(StringLike.scala:284)
	at scala.collection.immutable.StringOps.toDouble(StringOps.scala:29)
	at org.apache.spark.examples.SparkHdfsLRDP$.parsePoint(SparkHdfsLRDP.scala:44)
	at org.apache.spark.examples.SparkHdfsLRDP$$anonfun$1.apply(SparkHdfsLRDP.scala:81)
	at org.apache.spark.examples.SparkHdfsLRDP$$anonfun$1.apply(SparkHdfsLRDP.scala:81)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.TraversableOnce$class.reduceLeft(TraversableOnce.scala:185)
	at scala.collection.AbstractIterator.reduceLeft(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$reduce$1$$anonfun$15.apply(RDD.scala:1012)
	at org.apache.spark.rdd.RDD$$anonfun$reduce$1$$anonfun$15.apply(RDD.scala:1010)
	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:2118)
	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:2118)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
